question_id,question,key_phrases,feedback,correct_answer
1,What is overfitting in machine learning?,"Overfitting happens when a model learns patterns too specific to the training data, reducing its ability to generalize to new data. Regularization, cross-validation, and increasing dataset size can help prevent it.;high variance;training data;test data","Overfitting happens when a model learns the training data too well, capturing noise instead of patterns. A good solution is regularization or more training data.","Overfitting happens when a model learns the training data too well, capturing noise instead of patterns. A good solution is regularization or more training data."
2,What is the difference between Supervised and Unsupervised Learning?,"Supervised Learning uses labeled data to train models for predictions, while Unsupervised Learning identifies hidden patterns in unlabeled data. Examples include classification for supervised learning and clustering for unsupervised learning.;unlabeled data;classification;clustering","Supervised learning uses labeled data, while unsupervised learning finds patterns in unlabeled data.","Supervised learning uses labeled data, while unsupervised learning finds patterns in unlabeled data."
3,What is the purpose of cross-validation?,Cross-validation helps assess a model's performance by splitting data into training and validation sets multiple times. It prevents overfitting and ensures the model generalizes well to unseen data. K-Fold cross-validation is a common method;k-fold;train-test split;model evaluation,Cross-validation helps evaluate a model's performance by splitting data into training and validation sets multiple times to reduce overfitting.,Cross-validation helps evaluate a model's performance by splitting data into training and validation sets multiple times to reduce overfitting.
4,What is the bias-variance tradeoff?,"The bias-variance tradeoff explains the balance between a simple model (high bias, underfitting) and a complex model (high variance, overfitting). The goal is to find a model that generalizes well by reducing both bias and variance;variance;overfitting;underfitting;generalization","The bias-variance tradeoff describes the balance between a model being too simple (high bias, underfitting) and too complex (high variance, overfitting).","The bias-variance tradeoff describes the balance between a model being too simple (high bias, underfitting) and too complex (high variance, overfitting)."
5,"What are Precision, Recall, and F1-score?","Precision measures how many predicted positives were actually correct, recall measures how many actual positives were found, and F1-score balances both. Precision is crucial when false positives matter, recall when false negatives matter, and F1-score when both are important;recall;f1-score;false positives;false negatives","Precision measures correctness of positive predictions, recall measures completeness, and F1-score balances both.","Precision measures correctness of positive predictions, recall measures completeness, and F1-score balances both."
